{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline: Echocardiogram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual pipeline for DCM download, decompress and classification of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "projectdir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(projectdir, 'src'))\n",
    "\n",
    "import d00_utils.db_utils as db\n",
    "from d02_intermediate.download_dcm import s3_download_decomp_dcm, dcmdir_to_jpgs_for_classification\n",
    "from d03_classification.predict_views import run_classify, agg_probabilities, predict_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name='instances_w_labels'\n",
    "train_test_ratio=0.5 \n",
    "downsample_ratio=0.001\n",
    "train=False\n",
    "#to get train_split100, set configs 1.0, 0.05, train=True\n",
    "\n",
    "dcm_path = os.path.join(os.path.expanduser('~/data'),'01_raw')\n",
    "\n",
    "#model_path = os.path.join(os.path.expanduser('~/models'), 'view_23_e5_class_11-Mar-2018')\n",
    "\n",
    "new_mod_direc = '~/dvv/usal_echo/src/d03_classification/echo_deeplearning/models/vgg_13/m1_usal/train/0'\n",
    "new_mod_name = 'model.ckpt-6460'\n",
    "model_path = os.path.join(os.path.expanduser(new_mod_direc), new_mod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_name = s3_download_decomp_dcm(dcm_path, table_name, train_test_ratio, downsample_ratio, train)\n",
<<<<<<< HEAD
    "dir_name = 'test_split50_downsampleby1000'"
=======
    "\n",
    "dir_name = 'test_downsampleby5/'\n",
    "#dir_name = 'test_split50_downsampleby1000'"
>>>>>>> e2673eb69f3ce2eb9c4e6eca9954027c240a213b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/02_intermediate/test_downsampleby5/\n"
     ]
    }
   ],
   "source": [
    "dcm_dir = os.path.join(dcm_path, dir_name)\n",
    "img_dir = os.path.join(os.path.expanduser('~/data'),'02_intermediate', dir_name)\n",
    "print(img_dir)\n",
    "dcmdir_to_jpgs_for_classification(dcm_dir, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/ubuntu/dvv/usal_echo/src/d03_classification/nn.py:125: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/ubuntu/dvv/usal_echo/src/d03_classification/vgg.py:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Variables to save should be passed in a dict or a list: [<tf.Variable 'network/conv1_1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'network/conv1_1/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'network/conv1_2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'network/conv1_2/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'network/conv2_1/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'network/conv2_1/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'network/conv2_2/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'network/conv2_2/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'network/conv3_1/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_1/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv3_2/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_2/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv3_3/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_3/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv4_1/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv4_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_2/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv4_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_3/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_1/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_2/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_3/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/fc6/W:0' shape=(25088, 4096) dtype=float32_ref>, <tf.Variable 'network/fc6/b:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'network/fc7/W:0' shape=(4096, 4096) dtype=float32_ref>, <tf.Variable 'network/fc7/b:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'network/fc8/W:0' shape=(4096, 23) dtype=float32_ref>, <tf.Variable 'network/fc8/b:0' shape=(23,) dtype=float32_ref>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9c735a6db078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dvv/usal_echo/src/d03_classification/predict_views.py\u001b[0m in \u001b[0;36mrun_classify\u001b[0;34m(img_dir, model_path, if_exists, feature_dim)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mdf_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'output_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mview_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dvv/usal_echo/src/d03_classification/predict_views.py\u001b[0m in \u001b[0;36m_classify\u001b[0;34m(img_dir, feature_dim, label_dim, model_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    837\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    838\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     saveables = saveable_object_util.validate_and_slice_inputs(\n\u001b[0;32m--> 494\u001b[0;31m         names_to_saveables)\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mvalidate_and_slice_inputs\u001b[0;34m(names_to_saveables)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \"\"\"\n\u001b[1;32m    330\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_list_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mop_list_to_dict\u001b[0;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     raise TypeError(\"Variables to save should be passed in a dict or a \"\n\u001b[0;32m--> 229\u001b[0;31m                     \"list: %s\" % op_list)\n\u001b[0m\u001b[1;32m    230\u001b[0m   \u001b[0;31m# When ResourceVariables are converted to Tensors, read ops are added to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;31m# graph. Sorting the op_list ensures that the resulting graph is always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Variables to save should be passed in a dict or a list: [<tf.Variable 'network/conv1_1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'network/conv1_1/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'network/conv1_2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'network/conv1_2/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'network/conv2_1/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'network/conv2_1/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'network/conv2_2/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'network/conv2_2/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'network/conv3_1/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_1/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv3_2/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_2/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv3_3/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'network/conv3_3/b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'network/conv4_1/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv4_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_2/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv4_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv4_3/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_1/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_2/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/conv5_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'network/conv5_3/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'network/fc6/W:0' shape=(25088, 4096) dtype=float32_ref>, <tf.Variable 'network/fc6/b:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'network/fc7/W:0' shape=(4096, 4096) dtype=float32_ref>, <tf.Variable 'network/fc7/b:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'network/fc8/W:0' shape=(4096, 23) dtype=float32_ref>, <tf.Variable 'network/fc8/b:0' shape=(23,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "run_classify(img_dir, model_path, if_exists='append', feature_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "chkp.print_tensors_in_checkpoint_file(model_path, tensor_name='', all_tensors=False)"
=======
    "run_classify(img_dir, model_path, if_exists='append', feature_dim=1)"
>>>>>>> test_predict
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "old_mod_path = '/home/ubuntu/models/view_23_e5_class_11-Mar-2018'\n",
    "\n",
    "chkp.print_tensors_in_checkpoint_file(old_mod_path, tensor_name='', all_tensors=False)"
=======
    "agg_probabilities(if_exists='append')"
>>>>>>> test_predict
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/ubuntu/models/view_23_e5_class_11-Mar-2018\n",
    "# WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1272: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    "# Instructions for updating:\n",
    "# Use standard file APIs to check for files with this prefix.\n",
    "# INFO:tensorflow:Restoring parameters from /home/ubuntu/models/view_23_e5_class_11-Mar-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:tensorflow:Scale of 0 disables regularizer.\n",
    "# /home/ubuntu/dvv/usal_echo/src/d03_classification/echo_deeplearning/models/vgg_13/m1_usal/train/0/model.ckpt-3200\n",
    "# WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1272: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    "# Instructions for updating:\n",
    "# Use standard file APIs to check for files with this prefix.\n",
    "# INFO:tensorflow:Restoring parameters from /home/ubuntu/dvv/usal_echo/src/d03_classification/echo_deeplearning/models/vgg_13/m1_usal/train/0/model.ckpt-3200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/usal_echo/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "agg_probabilities(if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_views(if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['probabilities_frames', 'predictions', 'probabilities_instances', 'test1000_for_m1', 'probabilities_frames_test', 'test_probabilities_instances', 'test_probabilities_frames', 'evaluations', 'ground_truths', 'test_predictions', 'test1000_for_m2_m3', 'evaluation']\n"
     ]
    }
   ],
   "source": [
    "io_class = db.dbReadWriteClassification()\n",
    "io_class.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>date_run</th>\n",
       "      <th>view23_pred</th>\n",
       "      <th>view4_dev</th>\n",
       "      <th>view4_seg</th>\n",
       "      <th>prediction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>126557</td>\n",
       "      <td>a_126557_EF74LO2Z</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>plax_plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>126751</td>\n",
       "      <td>a_126751_FDNHKCYK</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>126772</td>\n",
       "      <td>a_126772_FDNHO33T</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>126778</td>\n",
       "      <td>a_126778_FDNHPQ07</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>126781</td>\n",
       "      <td>a_126781_FDNHQ1M9</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      study_id          file_name                    model_name  \\\n",
       "3103    126557  a_126557_EF74LO2Z  view_23_e5_class_11-Mar-2018   \n",
       "3104    126751  a_126751_FDNHKCYK  view_23_e5_class_11-Mar-2018   \n",
       "3105    126772  a_126772_FDNHO33T  view_23_e5_class_11-Mar-2018   \n",
       "3106    126778  a_126778_FDNHPQ07  view_23_e5_class_11-Mar-2018   \n",
       "3107    126781  a_126781_FDNHQ1M9  view_23_e5_class_11-Mar-2018   \n",
       "\n",
       "                        date_run view23_pred view4_dev view4_seg  \\\n",
       "3103  2019-08-14 14:06:23.830776   plax_plax      plax      plax   \n",
       "3104  2019-08-14 14:06:23.830776         a4c       a4c       a4c   \n",
       "3105  2019-08-14 14:06:23.830776       other     other     other   \n",
       "3106  2019-08-14 14:06:23.830776       other     other     other   \n",
       "3107  2019-08-14 14:06:23.830776         a4c       a4c       a4c   \n",
       "\n",
       "      prediction_id  \n",
       "3103           3104  \n",
       "3104           3105  \n",
       "3105           3106  \n",
       "3106           3107  \n",
       "3107           3108  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = io_class.get_table('predictions')\n",
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>date_run</th>\n",
       "      <th>view23_pred</th>\n",
       "      <th>view4_dev</th>\n",
       "      <th>view4_seg</th>\n",
       "      <th>prediction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43763</td>\n",
       "      <td>a_43763_1LHFYKEZ</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45076</td>\n",
       "      <td>a_45076_43IX4IH1</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>plax_plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46919</td>\n",
       "      <td>a_46919_7SQZPLEJ</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49268</td>\n",
       "      <td>a_49268_CSTYB214</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>plax_plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50521</td>\n",
       "      <td>a_50521_EAKXA40T</td>\n",
       "      <td>view_23_e5_class_11-Mar-2018</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id         file_name                    model_name  \\\n",
       "0     43763  a_43763_1LHFYKEZ  view_23_e5_class_11-Mar-2018   \n",
       "1     45076  a_45076_43IX4IH1  view_23_e5_class_11-Mar-2018   \n",
       "2     46919  a_46919_7SQZPLEJ  view_23_e5_class_11-Mar-2018   \n",
       "3     49268  a_49268_CSTYB214  view_23_e5_class_11-Mar-2018   \n",
       "4     50521  a_50521_EAKXA40T  view_23_e5_class_11-Mar-2018   \n",
       "\n",
       "                     date_run view23_pred view4_dev view4_seg  prediction_id  \n",
       "0  2019-08-14 14:06:23.830776         a4c       a4c       a4c              1  \n",
       "1  2019-08-14 14:06:23.830776   plax_plax      plax      plax              2  \n",
       "2  2019-08-14 14:06:23.830776         a4c       a4c       a4c              3  \n",
       "3  2019-08-14 14:06:23.830776   plax_plax      plax      plax              4  \n",
       "4  2019-08-14 14:06:23.830776         a4c       a4c       a4c              5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>date_run</th>\n",
       "      <th>view23_pred</th>\n",
       "      <th>view4_dev</th>\n",
       "      <th>view4_seg</th>\n",
       "      <th>prediction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>126557</td>\n",
       "      <td>a_126557_EF74LO2Z</td>\n",
       "      <td>view_23_retrain_14-Aug-2019</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>plax_plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>plax</td>\n",
       "      <td>3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>126751</td>\n",
       "      <td>a_126751_FDNHKCYK</td>\n",
       "      <td>view_23_retrain_14-Aug-2019</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>126772</td>\n",
       "      <td>a_126772_FDNHO33T</td>\n",
       "      <td>view_23_retrain_14-Aug-2019</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>126778</td>\n",
       "      <td>a_126778_FDNHPQ07</td>\n",
       "      <td>view_23_retrain_14-Aug-2019</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>126781</td>\n",
       "      <td>a_126781_FDNHQ1M9</td>\n",
       "      <td>view_23_retrain_14-Aug-2019</td>\n",
       "      <td>2019-08-14 14:06:23.830776</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>a4c</td>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      study_id          file_name                   model_name  \\\n",
       "3103    126557  a_126557_EF74LO2Z  view_23_retrain_14-Aug-2019   \n",
       "3104    126751  a_126751_FDNHKCYK  view_23_retrain_14-Aug-2019   \n",
       "3105    126772  a_126772_FDNHO33T  view_23_retrain_14-Aug-2019   \n",
       "3106    126778  a_126778_FDNHPQ07  view_23_retrain_14-Aug-2019   \n",
       "3107    126781  a_126781_FDNHQ1M9  view_23_retrain_14-Aug-2019   \n",
       "\n",
       "                        date_run view23_pred view4_dev view4_seg  \\\n",
       "3103  2019-08-14 14:06:23.830776   plax_plax      plax      plax   \n",
       "3104  2019-08-14 14:06:23.830776         a4c       a4c       a4c   \n",
       "3105  2019-08-14 14:06:23.830776       other     other     other   \n",
       "3106  2019-08-14 14:06:23.830776       other     other     other   \n",
       "3107  2019-08-14 14:06:23.830776         a4c       a4c       a4c   \n",
       "\n",
       "      prediction_id  \n",
       "3103           3104  \n",
       "3104           3105  \n",
       "3105           3106  \n",
       "3106           3107  \n",
       "3107           3108  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mod_name = 'view_23_retrain_14-Aug-2019'\n",
    "\n",
    "mask = df.duplicated(subset='file_name')\n",
    "\n",
    "df.loc[mask, 'model_name'] = new_mod_name\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_class.save_to_db(df, 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d03_classification.evaluate_views import evaluate_views"
=======
   "source": [
<<<<<<< HEAD
    "evaluate_views(dir_name, model_name, datetime.date.today(), study_filter=None, if_exists=\"append\") "
=======
    "evaluate_views(dir_name, model_name, datetime.date.today(), study_filter=None, if_exists=\"append\")"
>>>>>>> test_predict
>>>>>>> e2673eb69f3ce2eb9c4e6eca9954027c240a213b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'img_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'img_dir'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f8826b16672f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_views\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'20190814'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, view_mapping='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dvv/usal_echo/src/d03_classification/evaluate_views.py\u001b[0m in \u001b[0;36mevaluate_views\u001b[0;34m(img_dir, model_name, date_run, study_filter, if_exists)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mview_mapping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"view4_dev\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"view4_seg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         eval_out = evaluate_view_map(\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dvv/usal_echo/src/d03_classification/evaluate_views.py\u001b[0m in \u001b[0;36mevaluate_view_map\u001b[0;34m(img_dir, model_name, date_run, view_mapping, study_filter)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mpredict_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date_run\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/usal_echo/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'img_dir'"
     ]
    }
   ],
   "source": [
    "evaluate_views(img_dir, model_name=new_mod_name, date_run='20190814')#, view_mapping='')"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_class.get_table('evaluations')"
>>>>>>> test_predict
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual pipeline for the segmentation of image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d02_intermediate.create_seg_view import create_seg_view \n",
    "from d04_segmentation.segment_view import run_segment\n",
    "from d04_segmentation.generate_masks import generate_masks\n",
    "from d04_segmentation.evaluate_masks import evaluate_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_dir = os.path.join(dcm_path, dir_name)\n",
    "dcm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.expanduser('~/models'))\n",
    "run_segment(dcm_dir, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_seg_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_views = db.dbReadWriteViews()\n",
    "io_views.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_views.get_table('frames_by_volume_mask').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_views.get_table('chords_by_volume_mask').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_masks(dcm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_segmentation = db.dbReadWriteSegmentations()\n",
    "io_segmentation.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_masks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_courtney)",
   "language": "python",
   "name": "conda_courtney"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
